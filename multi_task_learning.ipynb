{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muli-task learning\n",
    "This notebook mostly mirrors the simple_captions notebook but predicts three different outputs instead of just captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/data.json') as infile:  \n",
    "    data = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78869"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['moves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pawn from file d takes on e8 with promotion to queen with check <End>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pieceToWord(notation, verbose=False):\n",
    "    '''\n",
    "    Returns a short sentence describing a piece and its position\n",
    "    '''\n",
    "    \n",
    "    pieces = {\n",
    "        \"B\": \"Bishop\",\n",
    "        \"R\": \"Rook\",\n",
    "        \"K\": \"King\",\n",
    "        \"Q\": \"Queen\",\n",
    "        \"N\": \"Knight\"\n",
    "    }\n",
    "    \n",
    "    length = len(notation)\n",
    "    \n",
    "    if length == 0:\n",
    "        return \"Pawn\"\n",
    "    \n",
    "    if length == 1:\n",
    "        if notation.islower(): # Pawn\n",
    "            if verbose:\n",
    "                return \"Pawn from file \" + notation\n",
    "            else:\n",
    "                return \"Pawn\"\n",
    "        else: # Higher piece\n",
    "            return pieces[notation]\n",
    "    \n",
    "    piece = pieces[notation[0]]\n",
    "    \n",
    "    if not verbose:\n",
    "        return piece\n",
    "    \n",
    "    if length == 2:\n",
    "        if notation[1].isdigit(): # rank\n",
    "            return piece + \" from rank \" + notation[1]\n",
    "        else: # file\n",
    "            return piece + \" from file \" + notation[1]\n",
    "    \n",
    "    if length == 3: # rank and file\n",
    "        return piece + \" from square \" + notation[1:] \n",
    "\n",
    "def moveToSentence(move, verbose=False):\n",
    "    '''\n",
    "    Translates a move in the algebraic notation into a caption.\n",
    "    '''\n",
    "    \n",
    "    pieces = {\n",
    "        \"B\": \"Bishop\",\n",
    "        \"R\": \"Rook\",\n",
    "        \"K\": \"King\",\n",
    "        \"Q\": \"Queen\",\n",
    "        \"N\": \"Knight\"\n",
    "    }\n",
    "    \n",
    "    action = \" to \" # Default action is move\n",
    "    modifier = \"\" # Default no modifier\n",
    "    \n",
    "    if \"+\" in move: # Check\n",
    "        if verbose:\n",
    "            modifier = \" with check\"\n",
    "        move = move[:-1]\n",
    "    \n",
    "    if \"#\" in move: # Checkmate\n",
    "        if verbose:\n",
    "            modifier = \" with checkmate\"\n",
    "        move = move[:-1]\n",
    "        \n",
    "    if \"=\" in move: # Pawn promotion\n",
    "        if verbose:\n",
    "            modifier = \" with promotion to \" + pieces[move[-1:]].lower() + modifier\n",
    "        move = move[:-2]\n",
    "        \n",
    "    if \"e.p.\" in move: # En passant\n",
    "        move = move.replace('e.p.', '')\n",
    "        if verbose:\n",
    "            return  \" en passant\" + modifier\n",
    "    \n",
    "    # Special cases\n",
    "    if \"O-O\" == move: # Kingside caste\n",
    "        return \"Kingside castle\" + modifier\n",
    "    \n",
    "    if move == \"O-O-O\": # Queenside castle\n",
    "        return \"Queenside castle\" + modifier    \n",
    "        \n",
    "    # extract final position\n",
    "    position = move[-2:]\n",
    "    move = move[:-2]\n",
    "        \n",
    "    if \"x\" in move: # Capture\n",
    "        action = \" takes on \"\n",
    "        move = move[:-1]\n",
    "        \n",
    "    piece = pieceToWord(move, verbose)\n",
    "    \n",
    "    return piece + action + position + modifier + \" <End>\"\n",
    "\n",
    "moveToSentence(\"dxe8=Q+\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnbqkbnr/pppppppp/8/8/2P5/8/PP1PPPPP/RNBQKBNR\n",
      "rnbqkbnr/pppppppp/8/8/2P5/8/PP1PPPPP/RNBQKBNR\n"
     ]
    }
   ],
   "source": [
    "# Helper methods to convert fens to the matrix representation\n",
    "import numpy as np\n",
    "\n",
    "def indexToArray(i, len_ = 13):\n",
    "    '''\n",
    "    Converts an index into a one-hot-encoded vector.\n",
    "    i - the index of the 1.\n",
    "    len_ - (optional) the len of the one-hot-vector. Default is 12.\n",
    "    returns a vector of length len_\n",
    "    '''\n",
    "    \n",
    "    array = [0] * len_\n",
    "    \n",
    "    if(i >= 0 and i < len(array)):\n",
    "        array[i] = 1\n",
    "        \n",
    "    return array\n",
    "\n",
    "def fenToMatrix(fen):\n",
    "    '''\n",
    "    Converts a fen string to a 8x8x16 matrix.\n",
    "    fen - a string in the fen notation\n",
    "    returns a 8x8x12 matrix\n",
    "    '''\n",
    "    \n",
    "    # 'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR'\n",
    "    pieces = {\n",
    "        '': indexToArray(0),\n",
    "        'r': indexToArray(1),\n",
    "        'n': indexToArray(2),\n",
    "        'b': indexToArray(3),\n",
    "        'q': indexToArray(4),\n",
    "        'k': indexToArray(5),\n",
    "        'p': indexToArray(6),\n",
    "        'P': indexToArray(7),\n",
    "        'R': indexToArray(8),\n",
    "        'N': indexToArray(9),\n",
    "        'B': indexToArray(10),\n",
    "        'Q': indexToArray(11),\n",
    "        'K': indexToArray(12),\n",
    "    }\n",
    "    \n",
    "    matrix = []\n",
    "    row = []\n",
    "    \n",
    "    for c in fen:\n",
    "        try:\n",
    "            cInt = int(c)\n",
    "            \n",
    "            for i in range(cInt):\n",
    "                row.append(pieces[''])\n",
    "        except: # c can not be cast as integer\n",
    "            if c == '/':\n",
    "                matrix.append(row)\n",
    "                row = []\n",
    "            else:\n",
    "                row.append(pieces[c]) \n",
    "    matrix.append(row)\n",
    "                \n",
    "    return np.array(matrix)\n",
    "\n",
    "def matrixToFen(matrix):\n",
    "    '''\n",
    "    Converts 8x8x13 matrix to a fen string.\n",
    "    matrix - a 8x8x13 matrix\n",
    "    returns a fen string\n",
    "    '''\n",
    "    \n",
    "    # 'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR'\n",
    "    pieces = [\n",
    "        '',\n",
    "        'r',\n",
    "        'n',\n",
    "        'b',\n",
    "        'q',\n",
    "        'k',\n",
    "        'p',\n",
    "        'P',\n",
    "        'R',\n",
    "        'N',\n",
    "        'B',\n",
    "        'Q',\n",
    "        'K',\n",
    "    ]\n",
    "        \n",
    "    matrix = (matrix > 0).astype(int) * (matrix == matrix.max(axis=2)[:,:,None]).astype(int)\n",
    "        \n",
    "    fen = \"\"\n",
    "     \n",
    "    for i in range(8):\n",
    "        row = matrix[i]\n",
    "        empty = 0\n",
    "        \n",
    "        for j in range(8):\n",
    "            square = row[j]\n",
    "            piece_found = False\n",
    "            \n",
    "            for k in range(len(pieces)):\n",
    "                piece = square[k]\n",
    "                \n",
    "                if piece == 1:\n",
    "                    if pieces[k] == '':\n",
    "                        empty += 1\n",
    "                    else:\n",
    "                        if empty > 0:\n",
    "                            fen += str(empty)\n",
    "                            empty = 0\n",
    "                        fen += pieces[k]               \n",
    "                \n",
    "        if empty > 0:\n",
    "            fen += str(empty)  \n",
    "            \n",
    "        if i < 7:\n",
    "            fen += \"/\"  \n",
    "            \n",
    "    return fen\n",
    "\n",
    "def similarityScore(y_true, y_pred):\n",
    "    '''\n",
    "    Calculates the similarity between to chess position\n",
    "    The result is the number of squares that have the same piece/are empty accross the two boards\n",
    "    y_true - an 8x8x12 matrix\n",
    "    y_pred - and 8x8x12 matrix\n",
    "    returns a similarity between 0 and 1\n",
    "    '''\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    y_true = (y_true > 0).astype(int) * (y_true == y_true.max(axis=2)[:,:,None]).astype(int)\n",
    "    y_pred = (y_pred > 0).astype(int) * (y_pred == y_pred.max(axis=2)[:,:,None]).astype(int)\n",
    "    \n",
    "    diff = (y_true - y_pred) ** 2\n",
    "    \n",
    "    wrong = np.sum(diff) \n",
    "    \n",
    "    return 1 - (wrong / 32)  # Two boards can at most have 32 different fields (or they can have 16 fields where different units are places which also results in a wrong-count of 32) \n",
    "    \n",
    "print(data['fens'][0][0])\n",
    "print(matrixToFen(fenToMatrix(data['fens'][0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "pieces = [\"Pawn\", \"Rook\", \"Knight\", \"Bishop\", \"Queen\", \"King\"]\n",
    "files = list('abcdefgh')\n",
    "ranks = list('12345678')\n",
    "squares = [f+r for r in ranks for f in files]\n",
    "\n",
    "# Basic words in sentence\n",
    "vocab = {\n",
    "    \"<Pad>\": 0,\n",
    "    \"<End>\": 1,\n",
    "    \"Kingside\": 2,\n",
    "    \"castle\": 3,\n",
    "    \"Queenside\": 4,\n",
    "    \"takes\": 5,\n",
    "    \"on\": 6,   \n",
    "    \"to\": 7,\n",
    "}\n",
    "\n",
    "if verbose:\n",
    "    vocab[\"en\"] = 8\n",
    "    vocab[\"passant\"] = 9\n",
    "    vocab[\"with\"] = 10\n",
    "    vocab[\"check\"] = 11\n",
    "    vocab[\"checkmate\"] = 12\n",
    "    vocab[\"promotion\"] = 13\n",
    "    vocab[\"from\"] = 14\n",
    "    vocab[\"file\"] = 15\n",
    "    vocab[\"rank\"] = 16\n",
    "    vocab[\"square\"] = 17\n",
    "    \n",
    "    # Files\n",
    "    for file in files:\n",
    "        vocab[file] = len(vocab)\n",
    "\n",
    "    # Ranks\n",
    "    for rank in ranks:\n",
    "        vocab[rank] = len(vocab)\n",
    "        \n",
    "# Pieces\n",
    "for piece in pieces:\n",
    "    vocab[piece] = len(vocab)\n",
    "    vocab[piece.lower()] = len(vocab)\n",
    "    \n",
    "# Squares\n",
    "for square in squares:\n",
    "    vocab[square] = len(vocab)\n",
    "    \n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c720c362264d43875a842c823ee5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78869), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined 24083414\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "combined = []\n",
    "\n",
    "for i in tqdm(range(len(data['fens']))):\n",
    "    game = data['moves'][i]\n",
    "    fens = data['fens'][i]\n",
    "    \n",
    "    start = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR\"\n",
    "    \n",
    "    for j in range(len(game)):\n",
    "        if j == 0: # First move\n",
    "            fen = [start, fens[j]]\n",
    "        else:\n",
    "            fen = [fens[j-1], fens[j]]\n",
    "            \n",
    "        sentence = moveToSentence(game[j]).split(' ')\n",
    "        \n",
    "        for i in range(len(sentence)):\n",
    "            combined.append([i, game[j], fen])\n",
    "                \n",
    "print(\"Combined\", len(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, combined, vocab, verbose):\n",
    "        'Initialization'\n",
    "        self.batch_size = 64\n",
    "        self.combined = combined\n",
    "        self.vocab = vocab\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.combined) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        combined = self.combined[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(combined)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __data_generation(self, combined):\n",
    "        'Generates data containing batch_size samples' \n",
    "        from_matrices = []\n",
    "        to_matrices = []\n",
    "        sentences = []\n",
    "        targets = []\n",
    "             \n",
    "        for i, move, fens in combined:\n",
    "            from_matrix = fenToMatrix(fens[0])\n",
    "            to_matrix = fenToMatrix(fens[1])\n",
    "            \n",
    "            from_matrices.append(from_matrix)\n",
    "            to_matrices.append(to_matrix)\n",
    "            \n",
    "            sentence = moveToSentence(move, self.verbose).split(' ')\n",
    "            sentence = [self.vocab[word] for word in sentence]\n",
    "            \n",
    "            target = np.zeros(len(vocab))\n",
    "            target[sentence[i]] = 1\n",
    "            sentence = sentence[:i]\n",
    "            sentence = sentence + [0] * (15 - len(sentence)) # Add padding\n",
    "\n",
    "            sentences.append(sentence)\n",
    "            targets.append(target)\n",
    "            \n",
    "        from_matrices = np.array(from_matrices)\n",
    "        to_matrices = np.array(to_matrices)\n",
    "        sentences = np.array(sentences)\n",
    "        targets = np.array(targets)\n",
    "            \n",
    "        return [from_matrices, to_matrices, sentences], [to_matrices, targets]\n",
    "    \n",
    "np.random.shuffle(combined)\n",
    "training_generator = DataGenerator(combined[:23000000], vocab, verbose)\n",
    "validation_generator = DataGenerator(combined[23000000:], vocab, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 8, 8, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator[0][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 8, 13)          0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 256)               1509120   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 8, 8, 13)          1509696   \n",
      "=================================================================\n",
      "Total params: 3,018,816\n",
      "Trainable params: 3,018,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('autoencoder1.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Flatten, Reshape, GRU, Embedding, concatenate\n",
    "from keras import metrics\n",
    "\n",
    "def Encoder():\n",
    "    from_matrix = Input(shape=(8, 8, 13))\n",
    "    to_matrix = Input(shape=(8, 8, 13))\n",
    "    sentence = Input(shape=(10,))\n",
    "    \n",
    "    encoder = load_model('autoencoder1.h5').get_layer('model_2')\n",
    "    encoder.name = 'encoder1'\n",
    "    encoder.layers.pop(0)\n",
    "    x1 = encoder(from_matrix)\n",
    "    x1 = Model(inputs=from_matrix, outputs=x1)\n",
    "    \n",
    "    encoder = load_model('autoencoder1.h5').get_layer('model_2')\n",
    "    encoder.name = 'encoder2'\n",
    "    encoder.layers.pop(0)\n",
    "    x2 = encoder(to_matrix)\n",
    "    x2 = Model(inputs=to_matrix, outputs=x2)\n",
    "\n",
    "    y = Embedding(len(vocab), 50, mask_zero=True)(sentence)\n",
    "    y = GRU(124, activation='relu')(y)\n",
    "    y = Model(inputs=sentence, outputs=y)\n",
    "    \n",
    "    z = concatenate([x1.output, x2.output, y.output])\n",
    "    \n",
    "    return Model(inputs=[x1.input, x2.input, y.input], outputs=z)\n",
    "\n",
    "def Decoder():\n",
    "    X = Input(shape=(636,))\n",
    "    \n",
    "    # Board state\n",
    "    d11 = Dense(1024, activation='relu')(X)\n",
    "    d12 = Dense(8*8*13, activation='linear')(d11)\n",
    "    r1 = Reshape((8, 8, 13), name=\"board\")(d12)\n",
    "    \n",
    "    # Caption\n",
    "    d21 = Dense(256, activation='relu')(X)\n",
    "    d22 = Dense(len(vocab), activation='softmax', name=\"caption\")(d21)\n",
    "    \n",
    "    return Model(X, [r1, d22])\n",
    "\n",
    "losses = [\"categorical_crossentropy\", \"categorical_crossentropy\"]\n",
    "metrics = {\n",
    "    \"board\": \"categorical_accuracy\",\n",
    "    \"caption\": \"categorical_accuracy\",\n",
    "}\n",
    "\n",
    "# define input to the model:\n",
    "X = [Input(shape=(8, 8, 13)), Input(shape=(8, 8, 13)), Input(shape=(None,))]\n",
    "\n",
    "# make the model:\n",
    "multi_task_model = Model(X, Decoder()(Encoder()(X)))\n",
    "\n",
    "# compile the model:\n",
    "multi_task_model.compile(optimizer='adam', loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 8, 8, 13)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8, 8, 13)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 636)          3088840     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 8, 8, 13), ( 1696430     model_5[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,785,270\n",
      "Trainable params: 4,785,270\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi_task_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "    50/359375 [..............................] - ETA: 17:01:20 - loss: 14.5171 - model_1_loss: 3.4003"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a4b5db8ea034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m multi_task_model.fit_generator(generator=training_generator,\n\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     epochs=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    221\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    421\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misatty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    391\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Train model on dataset\n",
    "multi_task_model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=1, verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
